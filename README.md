# Awesome-Talking-Head-Generation

A curated list of papers focused on talking head animation, talking head animation, intend to keep pace with the anticipated surge of research in the coming months. 

## 知识星球

If you're interested in this research field, feel free to scan the QR code and join our community. The community **follows SOTA research every day** and offers a wealth of **technical blogs, reports**, and **learning materials**.

如果你对该研究方向感兴趣，欢迎扫码加入社群。社群**每日跟进前沿研究**，并有大量**技术博客、报告、及学习资料**。

<img src="https://github.com/NanGoAI/Awesome-Talking-Head-Generation/blob/main/docs/QR-Code.png" style="zoom:50%;" align="center" />

------



## Table-of-Contents

[2D-Audio-Driven](#2D-Audio-Driven)

[2D-Video-Driven](#2D-Video-Driven)

[3D-Audio-Driven](#3D-Audio-Driven)

[Dataset](#Dataset)

## 2D-Audio-Driven

| arXiv Time | Title                                                        | Pub                                                          | Project Page                                                 | Code                                                    | Labels                   | Tech Blog                            |
| ---------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------- | ------------------------ | ------------------------------------ |
| **2024**   |                                                              |                                                              |                                                              |                                                         |                          |                                      |
| 09/24      | DreamHead: Learning Spatial-Temporal Correspondence via Hierarchical Diffusion for Audio-driven Talking Head Synthesis | [arXiv](https://arxiv.org/abs/2409.10281)                    |                                                              |                                                         | Emotional<br />Diffusion | [知识星球](https://t.zsxq.com/aTR6O) |
| 09/24      | DiffTED: One-shot Audio-driven TED Talk Video Generation with Diffusion-based Co-speech Gestures | [CVPRW 2024](https://openaccess.thecvf.com/content/CVPR2024W/HuMoGen/papers/Hogue_DiffTED_One-shot_Audio-driven_TED_Talk_Video_Generation_with_Diffusion-based_Co-speech_CVPRW_2024_paper.pdf) |                                                              |                                                         |                          | [知识星球](https://t.zsxq.com/X9cqD) |
| 09/24      | EMOdiffhead: Continuously Emotional Control in Talking Head Generation via Diffusion | [arXiv](https://arxiv.org/abs/2409.07255)                    |                                                              |                                                         | Emotional<br />Diffusion | [知识星球](https://t.zsxq.com/P4inI) |
| 09/24      | SVP: Style-Enhanced Vivid Portrait Talking Head Diffusion Model | [arXiv](https://arxiv.org/abs/2409.03270)                    |                                                              |                                                         |                          | [知识星球](https://t.zsxq.com/RmSR4) |
| 09/24      | PoseTalk: Text-and-Audio-based Pose Control and Motion Refinement for One-Shot Talking Head Generation | [arXiv](https://arxiv.org/abs/2409.02657)                    | [Project](https://junleen.github.io/projects/posetalk/)      |                                                         |                          | [知识星球](https://t.zsxq.com/14Yd5) |
| 09/24      | SegTalker: Segmentation-based Talking Face Generation with Mask-guided Local Editing | [arXiv](https://arxiv.org/abs/2409.03605)                    |                                                              |                                                         | StyleGAN<br />Editable   | [知识星球](https://t.zsxq.com/o0UQB) |
| 09/24      | KAN-Based Fusion of Dual-Domain for Audio-Driven Facial Landmarks Generation | [arXiv](https://www.arxiv.org/abs/2409.05330)                |                                                              |                                                         |                          |                                      |
| 09/24      | KMTalk: Speech-Driven 3D Facial Animationwith Key Motion Embedding | [ECCV 2024](https://arxiv.org/abs/2409.01113)                |                                                              | [Code](https://github.com/ffxzh/KMTalk)                 |                          |                                      |
| 09/24      | CyberHost: Taming Audio-driven Avatar Diffusion Model with Region Codebook Attention | [arXiv](https://arxiv.org/abs/2409.01876)                    | [Project](https://cyberhost.github.io/)                      |                                                         | Diffusion                |                                      |
| 09/24      | Loopy: Taming Audio-Driven Portrait Avatar with Long-Term Motion Dependency | [arXiv](https://arxiv.org/abs/2409.02634)                    | [Project](https://loopyavatar.github.io/)                    |                                                         | Diffusion                |                                      |
| 07/24      | EchoMimic: Lifelike Audio-Driven Portrait Animations through Editable Landmark Conditions | [arXiv](https://arxiv.org/abs/2407.08136)                    | [Project](https://badtobest.github.io/echomimic.html)        | [Code](https://github.com/BadToBest/EchoMimic)          | Diffusion                |                                      |
| 04/24      | VASA-1: Lifelike Audio-Driven Talking Faces Generated in Real Time |                                                              | [Project](https://www.microsoft.com/en-us/research/project/vasa-1/) |                                                         | Diffusion                |                                      |
| 03/24      | AniPortrait: Audio-Driven Synthesis of Photorealistic Portrait Animations | [arXiv](https://arxiv.org/abs/2403.17694)                    |                                                              | [Code](https://github.com/Zejun-Yang/AniPortrait)       | Diffusion                |                                      |
| 02/24      | Emote Portrait Alive: Generating Expressive Portrait Videos with Audio2Video Diffusion Model under Weak Conditions | [ECCV 2024](https://arxiv.org/abs/2402.17485)                | [Project](https://humanaigc.github.io/emote-portrait-alive/) |                                                         | Diffusion                |                                      |
| **2023**   |                                                              |                                                              |                                                              |                                                         |                          |                                      |
| 12/23      | VividTalk: One-Shot Audio-Driven Talking Head Generation Based on 3D Hybrid Prior | [arXiv](https://arxiv.org/abs/2312.01841)                    | [Project](https://humanaigc.github.io/vivid-talk/)           | [Code](https://github.com/HumanAIGC/VividTalk)          |                          |                                      |
| 01/23      | DiffTalk: Crafting Diffusion Models for Generalized Audio-Driven Portraits Animation | [CVPR 2023](https://openaccess.thecvf.com/content/CVPR2023/papers/Shen_DiffTalk_Crafting_Diffusion_Models_for_Generalized_Audio-Driven_Portraits_Animation_CVPR_2023_paper.pdf) | [Project](https://sstzal.github.io/DiffTalk/)                | [Code](https://github.com/sstzal/DiffTalk)              | Diffusion                |                                      |
| 01/23      | Diffused Heads: Diffusion Models Beat GANs on Talking-Face Generation | [WACV 2024](https://arxiv.org/abs/2301.03396)                | [Project](https://mstypulkowski.github.io/diffusedheads/)    | [Code](https://github.com/MStypulkowski/diffused-heads) | Diffusion                |                                      |
| **2022**   |                                                              |                                                              |                                                              |                                                         |                          |                                      |
| 11/22      | SadTalker: Learning Realistic 3D Motion Coefficients for Stylized Audio-Driven Single Image Talking Face Animation | [CVPR 2023](https://openaccess.thecvf.com/content/CVPR2023/html/Zhang_SadTalker_Learning_Realistic_3D_Motion_Coefficients_for_Stylized_Audio-Driven_Single_CVPR_2023_paper.html) | [Project](https://sadtalker.github.io/)                      | [Code](https://github.com/OpenTalker/SadTalker)         |                          |                                      |
| 11/22      | SPACE: Speech-driven Portrait Animation with Controllable Expression | [ICCV 2023](https://openaccess.thecvf.com/content/ICCV2023/papers/Gururani_SPACE_Speech-driven_Portrait_Animation_with_Controllable_Expression_ICCV_2023_paper.pdf) | [Project](https://deepimagination.cc/SPACE/)                 |                                                         |                          |                                      |
| 05/22      | EAMM: One-Shot Emotional Talking Face via Audio-Based Emotion-Aware Motion Model | [SIGGRAPH 2022](https://dl.acm.org/doi/abs/10.1145/3528233.3530745) | [Project](https://jixinya.github.io/projects/EAMM/)          | [Code](https://github.com/jixinya/EAMM/)                | Emotional                |                                      |
| **2021**   |                                                              |                                                              |                                                              |                                                         |                          |                                      |
| 04/21      | Audio-Driven Emotional Video Portraits                       | [CVPR 2021](https://openaccess.thecvf.com/content/CVPR2021/papers/Ji_Audio-Driven_Emotional_Video_Portraits_CVPR_2021_paper.pdf) | [Project](https://jixinya.github.io/projects/evp/)           | [Code](https://github.com/jixinya/EVP/)                 | Emotional                |                                      |
| **2020**   |                                                              |                                                              |                                                              |                                                         |                          |                                      |
| 08/20      | A Lip Sync Expert Is All You Need for Speech to Lip Generation In The Wild | [ACM MM 2020](https://arxiv.org/abs/2008.10010)              | [Project](http://cvit.iiit.ac.in/research/projects/cvit-projects/a-lip-sync-expert-is-all-you-need-for-speech-to-lip-generation-in-the-wild/) | [Code](https://github.com/Rudrabha/Wav2Lip)             |                          |                                      |
| 04/20      | MakeItTalk: Speaker-Aware Talking-Head Animation             | [SIGGRAPH Asia 2020](https://arxiv.org/abs/2004.12992)       | [Project](https://people.umass.edu/~yangzhou/MakeItTalk/)    | [Code](https://github.com/yzhou359/MakeItTalk)          |                          |                                      |

## 2D-Video-Driven

| arXiv Time | Title                                                        | Pub                                                          | Project Page                                                 | Code                                                         | Labels                   | Blog |
| ---------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------ | ---- |
| **2024**   |                                                              |                                                              |                                                              |                                                              |                          |      |
| 09/24      | LivePortrait: Efficient Portrait Animation with Stitching and Retargeting Control | [arXiv](https://arxiv.org/abs/2407.03168)                    | [Project](https://liveportrait.github.io/)                   | [Code](https://github.com/KwaiVGI/LivePortrait)              | Implicit-keypoints       |      |
| 07/24      | Learning Online Scale Transformation for Talking Head Video Generation | [arXiv](https://arxiv.org/html/2407.09965v1)                 |                                                              |                                                              | Implicit-keypoints       |      |
| 04/24      | EMOPortraits: Emotion-enhanced Multimodal One-shot Head Avatars | [CVPR 2024](https://arxiv.org/abs/2404.19110)                | [Project](https://neeek2303.github.io/EMOPortraits/)         | [Code](https://github.com/neeek2303/EMOPortraits)            | Emotional<br />3D-volume |      |
| **2022**   |                                                              |                                                              |                                                              |                                                              |                          |      |
| 07/22      | MegaPortraits: One-shot Megapixel Neural Head Avatars        | [ACM MM 2022](https://arxiv.org/abs/2207.07621)              | [Project](https://neeek2303.github.io/MegaPortraits/)        |                                                              | 3D-volume                |      |
| 03/22      | Thin-Plate Spline Motion Model for Image Animation           | [CVPR 2022](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhao_Thin-Plate_Spline_Motion_Model_for_Image_Animation_CVPR_2022_paper.pdf) |                                                              | [Code](https://github.com/yoyo-nb/Thin-Plate-Spline-Motion-Model) | Implicit-keypoints       |      |
| 03/22      | Depth-Aware Generative Adversarial Network for Talking Head Video Generation | [CVPR 2022](https://openaccess.thecvf.com/content/CVPR2022/papers/Hong_Depth-Aware_Generative_Adversarial_Network_for_Talking_Head_Video_Generation_CVPR_2022_paper.pdf) | [Project](https://harlanhong.github.io/publications/dagan.html) | [Code](https://github.com/harlanhong/CVPR2022-DaGAN)         | Implicit-kepints         |      |
| **2021**   |                                                              |                                                              |                                                              |                                                              |                          |      |
| 09/21      | PIRenderer: Controllable Portrait Image Generation via Semantic Neural Rendering | [ICCV 2021](https://openaccess.thecvf.com/content/ICCV2021/papers/Ren_PIRenderer_Controllable_Portrait_Image_Generation_via_Semantic_Neural_Rendering_ICCV_2021_paper.pdf) | [Project](https://renyurui.github.io/PIRender_web/)          | [Code](https://github.com/RenYurui/PIRender)                 |                          |      |
| **2020**   |                                                              |                                                              |                                                              |                                                              |                          |      |
| 11/20      | One-Shot Free-View Neural Talking-Head Synthesis for Video Conferencing | [CVPR 2021](https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_One-Shot_Free-View_Neural_Talking-Head_Synthesis_for_Video_Conferencing_CVPR_2021_paper.pdf) | [Project](https://nvlabs.github.io/face-vid2vid/)            | [Code](https://github.com/zhanglonghao1992/One-Shot_Free-View_Neural_Talking_Head_Synthesis) | Implicit-keypoints       |      |
| 03/20      | First Order Motion Model for Image Animation                 | [NeurIPS 2019](https://papers.nips.cc/paper_files/paper/2019/hash/31c0b36aef265d9221af80872ceb62f9-Abstract.html) |                                                              | [Code](https://github.com/AliaksandrSiarohin/first-order-model) | Implicit-keypoints       |      |

## 3D-Audio-Driven

| arXiv Time | Title                                                        | Pub                                                          | Project Page                                              | Code                                                 | Labels | Blog |
| ---------- | ------------------------------------------------------------ | ------------------------------------------------------------ | --------------------------------------------------------- | ---------------------------------------------------- | ------ | ---- |
| **2024**   |                                                              |                                                              |                                                           |                                                      |        |      |
| 09/24      | KMTalk: Speech-Driven 3D Facial Animation with Key Motion Embedding | [ECCV 2024](https://arxiv.org/abs/2409.01113)                |                                                           | [Code](https://github.com/ffxzh/KMTalk)              |        |      |
| 08/24      | UniTalker: Scaling up Audio-Driven 3D Facial Animation through A Unified Model | [ECCV 2024](https://arxiv.org/abs/2408.00762)                | [Project](https://x-niper.github.io/projects/UniTalker/)  | [Code](https://github.com/X-niper/UniTalker)         |        |      |
| **2023**   |                                                              |                                                              |                                                           |                                                      |        |      |
| 01/23      | CodeTalker: Speech-Driven 3D Facial Animation with Discrete Motion Prior | [CVPR 2023](https://arxiv.org/abs/2301.02379)                | [Project](https://doubiiu.github.io/projects/codetalker/) | [Code](https://github.com/Doubiiu/CodeTalker)        |        |      |
| **2021**   |                                                              |                                                              |                                                           |                                                      |        |      |
| 12/21      | FaceFormer: Speech-Driven 3D Facial Animation with Transformers | [CVPR 2022](https://openaccess.thecvf.com/content/CVPR2022/papers/Fan_FaceFormer_Speech-Driven_3D_Facial_Animation_With_Transformers_CVPR_2022_paper.pdf) | [Project](https://evelynfan.github.io/audio2face/)        | [Code](https://github.com/EvelynFan/FaceFormer)      |        |      |
| 04/21      | MeshTalk: 3D Face Animation From Speech Using Cross-Modality Disentanglement | [ICCV 2021](https://openaccess.thecvf.com/content/ICCV2021/papers/Richard_MeshTalk_3D_Face_Animation_From_Speech_Using_Cross-Modality_Disentanglement_ICCV_2021_paper.pdf) |                                                           | [Code](https://github.com/facebookresearch/meshtalk) |        |      |
|            |                                                              |                                                              |                                                           |                                                      |        |      |
|            |                                                              |                                                              |                                                           |                                                      |        |      |

## Dataset

| Dataset     | Year | Description                                                  | Link                                                        |
| ----------- | ---- | ------------------------------------------------------------ | ----------------------------------------------------------- |
| FEED        | 2024 | Facial **Extreme Emotions** Dataset, which is **multi-view** | [Download](https://github.com/neeek2303/FEED)               |
| CelebV-Text | 2023 | A large-scale, **high-quality**, and **diverse** facial **text-video** dataset | [Download](https://celebv-text.github.io/)                  |
| VFHQ        | 2022 | A **high-quality video face** dataset                        | [Download](https://liangbinxie.github.io/projects/vfhq/)    |
| HDTF        | 2021 | A large in-the-wild **high-resolution audio-visual** dataset | [Download](https://github.com/MRzzm/HDTF)                   |
| MEAD        | 2020 | **Multi-view Emotional Audio-visual** Dataset                | [Download](https://wywu.github.io/projects/MEAD/MEAD.html)  |
| VoxCeleb    | 2017 | A large scale **audio-visual** dataset                       | [Download](https://www.robots.ox.ac.uk/~vgg/data/voxceleb/) |

